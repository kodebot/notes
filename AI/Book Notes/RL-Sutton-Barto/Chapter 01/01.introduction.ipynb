{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "* people or animals learn by interacting with environment\n",
    "  * they acutely aware how environment responds to what they do\n",
    "  * they seek to influence what happens through their behaviour (action/interaction)\n",
    "\n",
    "* learning from interaction is foundational idea underlying all theories of learning and intelligence\n",
    "\n",
    "* the focus of this book is to explore computational approach to learning from interaction\n",
    "\n",
    "* the approach explored is called `reinforcement learning` which focused on goal-directed learning from interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Reinforcement Learning\n",
    "\n",
    "* is a learning of what to do\n",
    "\n",
    "* how to map situations (states) to actions - so as to maximise numerical reward signal\n",
    "\n",
    "* learner is not told which action to take, but instead discover which actions yield max reward by trying them\n",
    "\n",
    "* in most cases, action not only affect immediate reward but also next situation (state), thereby affecting future reward\n",
    "\n",
    "* two most important distinguishing features of RL are\n",
    "  * trial-and-error search\n",
    "  * delayed reward\n",
    "\n",
    "* problems of RL are formalised using ideas from dynamical systems theory - specifically\n",
    "  * as the optimal control of incompletely-known Markov Decision Process (MDP)\n",
    "\n",
    "* learning agent\n",
    "  * must be able to sense the state of its environment to some extend\n",
    "  * must be able to take actions that affect state\n",
    "  * must have goal(s) relating to state of the environment (for example reaching a particular state)\n",
    "\n",
    "* MDP does include state, action and goal in their simplest form without trivialising any of them\n",
    "\n",
    "* RL is considered ML paradigm of its own and different from other paradigms like supervised and unsupervised learning\n",
    "\n",
    "* exploration-exploitation trade off is common challenge in RL compared to other types of learning\n",
    "  * to obtain reward, RL agent must prefer actions that it has tried in the past and found to be effective (exploit)\n",
    "  * but to discover such actions, it has to try actions that it has not selected before (explore)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
