{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "* world is full of uncertainties that we want to measure\n",
    "\n",
    "* probability theoretical study of measuring certainty that an event will happen\n",
    "\n",
    "## Understanding Probability\n",
    "\n",
    "* probability is how strong we believe an event will happen\n",
    "\n",
    "  * usually referred in percent or 0.0 to 1.0\n",
    "\n",
    "* P(X) = 0.7\n",
    "\n",
    "  * notation for probability\n",
    "\n",
    "  * X - expected event\n",
    "\n",
    "* **Probability vs. Likelihood**\n",
    "\n",
    "  * `Probability` is quantifying predictions of events yet to happen (future)\n",
    "\n",
    "    * sum of probabilities of all mutually exclusive event must be 1\n",
    "  \n",
    "  * `Likelihood` is measuring the frequency of events already happened (past)\n",
    "\n",
    "    * sum of events totalling to 1 is not applicable for likelihood\n",
    "\n",
    "* complement\n",
    "\n",
    "  * probability of an event must be between 0 and 1\n",
    "\n",
    "  * this means we can calculate the probability of event not happening as\n",
    "\n",
    "    * P(not A) = 1 - P(A)\n",
    "\n",
    "      * this is referred to as complement rule\n",
    "\n",
    "* odds\n",
    "\n",
    "  * probability can be expressed as odds\n",
    "\n",
    "    * 7/3, 7:3, 2.333\n",
    "\n",
    "    * to convert odds to probability\n",
    "\n",
    "      * $ P(X) = \\frac{O(X)}{1 + O(X)} $\n",
    "\n",
    "    * probability to odds\n",
    "\n",
    "      * $ O(X) = \\frac{P(X)}{1 - P(X)} $\n",
    "\n",
    "  * odds are used in gambling/betting context as it it intuitive to understand\n",
    "\n",
    "    * for example odds of 2:1 means, the event is 2 times more likely to happen than not\n",
    "\n",
    "      * if expressed in percentage it will be 66.66 but 2:1 is more easy to understand\n",
    "\n",
    "### Probability vs Statistics\n",
    "\n",
    "* `probability` is purely theoretical of how likely an event is likely to happen, no data is required\n",
    "\n",
    "* on the other hand, `statistics` uses data to discover probability and provides many tools to describe data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Math\n",
    "* single probability of an event is known as `marginal probability` - P(X)\n",
    "\n",
    "### Joint Probabilities\n",
    "\n",
    "* probability that two or more separate events occurring together (simultaneously)\n",
    "\n",
    "* think of AND operator\n",
    "\n",
    "* joint probability is product of probabilities of individual events\n",
    "\n",
    "  * $P(A \\space AND \\space B) = P(A) \\times P(B)$\n",
    "\n",
    "  * this referred to as `product rule`\n",
    "\n",
    "### Union Probabilities\n",
    "\n",
    "* probability of getting one of many preferred events\n",
    "\n",
    "* think of OR operator\n",
    "\n",
    "* mutually exclusive events\n",
    "\n",
    "  * mutually exclusive events are events that cannot occur simultaneously\n",
    "\n",
    "    * for example rolling 1 and 6 in a single die simultaneously - cannot happen\n",
    "\n",
    "    * union probability of mutex events is sum of individual event probabilities\n",
    "\n",
    "      * $ P(A \\space OR \\space B) = P(A) + P(B) $\n",
    "\n",
    "* non mutually exclusive events\n",
    "\n",
    "  * events that can occur simultaneously\n",
    "\n",
    "    * example, getting 1 in a die or Head in a toss \n",
    "\n",
    "  * `sum rule of probability`\n",
    "\n",
    "    * $ P(A \\space OR \\space B) = P(A) + P (B) - P(A \\space AND \\space B) $\n",
    "\n",
    "      * we subtract $ P(A \\space AND \\space B) $ to remove double counted events\n",
    "\n",
    "    * this rule applies to mutually exclusive events too, it is just that the $ P(A \\space AND \\space B) $ will be zero\n",
    "\n",
    "### Conditional Probability and Bayes' Theorem\n",
    "\n",
    "* conditional probability is probability of A occurring given B has occurred\n",
    "\n",
    "  * $ P(A \\space GIVEN \\space B) \\space or \\space P(A|B) $\n",
    "\n",
    "* people get confused with this because they conflate P(A|B) and P(B|A) into something being equal but this is WRONG\n",
    "\n",
    "* example\n",
    "\n",
    "  * $ P(COFFEE | CANCER) = 0.85 $\n",
    "\n",
    "    * probability of people drink coffee given they have cancer is 85%\n",
    "\n",
    "    * this does not mean there is 85% chance of getting cancer if you drink coffee\n",
    "    \n",
    "      * $ P(CANCER | COFFEE) \\not = 0.85 $\n",
    "\n",
    "    * $ P(COFFEE) = 0.65 \\space and \\space P(CANCER) = 0.05 $\n",
    "\n",
    "      * we need to take rarity of the cancer into account not just the normality of drinking coffee\n",
    "\n",
    "    * based on the normality of coffee drinking and rarity of cancer, probability of getting cancer given drinking coffee is very low \n",
    "\n",
    "      * this can be calculated by Bayes's theorem\n",
    "\n",
    "      * $ P(A|B) =\\frac{P(B|A)P(A)}{P(B)} $\n",
    "\n",
    "      * memory trick - think of $P(A|B) \\space as \\space P(A)/P(B)$ then we just need to multiply numerator by $P(B|A)$\n",
    "\n",
    "      * so $ P(CANCER | COFFEE) = \\frac{0.85 \\times 0.005}{0.65} = 0.0065 $\n",
    "\n",
    "### Joint and Union Conditional Probabilities\n",
    "\n",
    "* example, consider we want to find the probability of coffee drinks AND cancer patients\n",
    "\n",
    "  * we can apply simple product rule $ P(COFFEE) \\times P(CANCER)$\n",
    "\n",
    "  * but if we already know $P(COFFEE|CANCER), then it makes sense to use $P(COFFEE|CANCER)$ instead of $ P(COFFEE) $\n",
    "\n",
    "    * this is because we are already talking about cancer patients\n",
    "\n",
    "  * this means, our product rule becomes\n",
    "\n",
    "    * $ P(A \\space AND \\space B) = P(A|B) \\times P(B) $ and this is equal to\n",
    "\n",
    "    * $ P(B \\space AND \\space A) = P(B|A) \\times P(A) $\n",
    "\n",
    "  * the way to reason about this is that if A and B are unrelated then $P(A|B) = P(A)$\n",
    "\n",
    "  * conditional probability sum rule would be\n",
    "\n",
    "    * $ P(A \\space OR \\space B) = P(A) + P(B) - P(A|B) \\times P(B) $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Distribution\n",
    "\n",
    "* measures how likely `k` success can happen from `n` trials given `p` probability of `n` being success\n",
    "\n",
    "* for example to determine 80% of success of 10 trial with underlying success probability of 90%, we can use binomial distribution \n",
    "\n",
    "    * p = 90%, n = 10 \n",
    "\n",
    "      * then we have around 26% chance of success (k) less than or equal to 8\n",
    "      * 38% chance for it being 9 \n",
    "      * 34% chance for it being 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Distribution\n",
    "\n",
    "* allows us to see the likelihood of different underlying probabilities for an event to occur given alpha success and beta failures\n",
    "\n",
    "* this is answering different question than Binomial distribution. In Binomial distribution, `p` is fixed an we are finding likelihood of `k` success from `n` trial\n",
    "\n",
    "* but here we don't know the probability, we have alpha success and beta failures, we are trying to find likelihood of different underlying probability p that would give us this alpha success and beta failure\n",
    "\n",
    "* example\n",
    "  * if we want to find probability 8/10 success would yield 90% or higher success rate, then we need to find the area between 0.9 and 1 in the beta distribution function\n",
    "\n",
    "  ![Image Beta Distribution](img/02.probability-1204064215.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1: 12.0%\n",
      "Exercise 2: 82.0%\n",
      "Exercise 3: 6.0%\n",
      "Exercise 4: 4.96%\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# 1. 30% chance of rain and 40% chance of umbrella arriving on time, so joint probability is\n",
    "print(f\"Exercise 1: {0.3 * 0.4 * 100}%\")\n",
    "\n",
    "# 2. 30% chance of rain, so 70% chance of not raining, 40% chance of umbrella arriving, so probability of not raining OR umbrella arriving is\n",
    "print(f\"Exercise 2: {((0.7 + 0.4) - (0.7 * 0.4)) * 100}%\")\n",
    "\n",
    "# 3. P(R) = 0.3, P(U) = 0.4, P(U|R) = 0.2, ans = P(R) X P(U|R)\n",
    "print(f\"Exercise 3: {0.3 * 0.2 * 100}%\")\n",
    "\n",
    "# 4. total passengers (n) = 137, p = 0.6, k = (137 - 50) = 87\n",
    "print(f\"Exercise 4: {binom.pmf(87, 137, 0.6) * 100:.2f}%\") # wrong answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
